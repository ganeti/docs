
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Design for virtual clusters support &#8212; Ganeti 3.0.2 documentation</title>
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/classic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css" />
    
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Developer notes" href="devnotes.html" />
    <link rel="prev" title="Automatized Upgrade Procedure for Ganeti" href="design-upgrade.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="devnotes.html" title="Developer notes"
             accesskey="N">next</a></li>
        <li class="right" >
          <a href="design-upgrade.html" title="Automatized Upgrade Procedure for Ganeti"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Ganeti 3.0.2 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Design for virtual clusters support</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="design-for-virtual-clusters-support">
<h1>Design for virtual clusters support<a class="headerlink" href="#design-for-virtual-clusters-support" title="Permalink to this headline">¶</a></h1>
<dl class="field-list simple">
<dt class="field-odd">Created</dt>
<dd class="field-odd"><p>2011-Oct-14</p>
</dd>
<dt class="field-even">Status</dt>
<dd class="field-even"><p>Partial Implementation</p>
</dd>
<dt class="field-odd">Ganeti-Version</dt>
<dd class="field-odd"><p>2.7.0</p>
</dd>
</dl>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Currently there are two ways to test the Ganeti (including HTools) code
base:</p>
<ul class="simple">
<li><p>unittests, which run using mocks as normal user and test small bits of
the code</p></li>
<li><p>QA/burnin/live-test, which require actual hardware (either physical or
virtual) and will build an actual cluster, with one machine to one
node correspondence</p></li>
</ul>
<p>The difference in time between these two is significant:</p>
<ul class="simple">
<li><p>the unittests run in about 1-2 minutes</p></li>
<li><p>a so-called ‘quick’ QA (without burnin) runs in about an hour, and a
full QA could be double that time</p></li>
</ul>
<p>On one hand, the unittests have a clear advantage: quick to run, not
requiring many machines, but on the other hand QA is actually able to
run end-to-end tests (including HTools, for example).</p>
<p>Ideally, we would have an intermediate step between these two extremes:
be able to test most, if not all, of Ganeti’s functionality but without
requiring actual hardware, full machine ownership or root access.</p>
</div>
<div class="section" id="current-situation">
<h2>Current situation<a class="headerlink" href="#current-situation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="ganeti">
<h3>Ganeti<a class="headerlink" href="#ganeti" title="Permalink to this headline">¶</a></h3>
<p>It is possible, given a manually built <code class="docutils literal notranslate"><span class="pre">config.data</span></code> and
<code class="docutils literal notranslate"><span class="pre">_autoconf.py</span></code>, to run the masterd under the current user as a
single-node cluster master. However, the node daemon and related
functionality (cluster initialisation, master failover, etc.) are not
directly runnable in this model.</p>
<p>Also, masterd only works as a master of a single node cluster, due to
our current “hostname” method of identifying nodes, which results in a
limit of maximum one node daemon per machine, unless we use multiple
name and IP aliases.</p>
</div>
<div class="section" id="htools">
<h3>HTools<a class="headerlink" href="#htools" title="Permalink to this headline">¶</a></h3>
<p>In HTools the situation is better, since it doesn’t have to deal with
actual machine management: all tools can use a custom LUXI path, and can
even load RAPI data from the filesystem (so the RAPI backend can be
tested), and both the ‘text’ backend for hbal/hspace and the input files
for hail are text-based, loaded from the file-system.</p>
</div>
</div>
<div class="section" id="proposed-changes">
<h2>Proposed changes<a class="headerlink" href="#proposed-changes" title="Permalink to this headline">¶</a></h2>
<p>The end-goal is to have full support for “virtual clusters”, i.e. be
able to run a “big” (hundreds of virtual nodes and towards thousands of
virtual instances) on a reasonably powerful, but single machine, under a
single user account and without any special privileges.</p>
<p>This would have significant advantages:</p>
<ul class="simple">
<li><p>being able to test end-to-end certain changes, without requiring a
complicated setup</p></li>
<li><p>better able to estimate Ganeti’s behaviour and performance as the
cluster size grows; this is something that we haven’t been able to
test reliably yet, and as such we still have not yet diagnosed
scaling problems</p></li>
<li><p>easier integration with external tools (and even with HTools)</p></li>
</ul>
<div class="section" id="masterd">
<h3><code class="docutils literal notranslate"><span class="pre">masterd</span></code><a class="headerlink" href="#masterd" title="Permalink to this headline">¶</a></h3>
<p>As described above, <code class="docutils literal notranslate"><span class="pre">masterd</span></code> already works reasonably well in a
virtual setup, as it won’t execute external programs and it shouldn’t
directly read files from the local filesystem (or at least not
virtualisation-related, as the master node can be a non-vm_capable
node).</p>
</div>
<div class="section" id="noded">
<h3><code class="docutils literal notranslate"><span class="pre">noded</span></code><a class="headerlink" href="#noded" title="Permalink to this headline">¶</a></h3>
<p>The node daemon executes many privileged operations, but they can be
split in a few general categories:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 20%" />
<col style="width: 31%" />
<col style="width: 49%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Category</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Solution</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>disk operations</p></td>
<td><p>Disk creation and
removal</p></td>
<td><p>Use only diskless or file-based
instances</p></td>
</tr>
<tr class="row-odd"><td><p>disk query</p></td>
<td><p>Node disk total/free,
used in node listing
and htools</p></td>
<td><p>Not supported currently, could use
file-based</p></td>
</tr>
<tr class="row-even"><td><p>hypervisor
operations</p></td>
<td><p>Instance start, stop
and query</p></td>
<td><p>Use the <em>fake</em> hypervisor</p></td>
</tr>
<tr class="row-odd"><td><p>instance
networking</p></td>
<td><p>Bridge existence query</p></td>
<td><p>Unprivileged operation, can be used
with an existing bridge at system
level or use NIC-less instances</p></td>
</tr>
<tr class="row-even"><td><p>instance OS
operations</p></td>
<td><p>OS add, OS rename,
export and import</p></td>
<td><p>Only used with non-diskless
instances; could work with custom OS
scripts that just <code class="docutils literal notranslate"><span class="pre">dd</span></code> without
mounting filesystems</p></td>
</tr>
<tr class="row-odd"><td><p>node networking</p></td>
<td><p>IP address management
(master ip), IP query,
etc.</p></td>
<td><p>Not supported; Ganeti will need to
work without a master IP; for the IP
query operations the test machine
would need externally-configured IPs</p></td>
</tr>
<tr class="row-even"><td><p>node add</p></td>
<td><ul class="simple">
<li></li>
</ul>
</td>
<td><p>SSH command must be adjusted</p></td>
</tr>
<tr class="row-odd"><td><p>node setup</p></td>
<td><p>ssh, /etc/hosts, so on</p></td>
<td><p>Can already be disabled from the
cluster config</p></td>
</tr>
<tr class="row-even"><td><p>master failover</p></td>
<td><p>start/stop the master
daemon</p></td>
<td><p>Doable (as long as we use a single
user), might get tricky w.r.t. paths
to executables</p></td>
</tr>
<tr class="row-odd"><td><p>file upload</p></td>
<td><p>Uploading of system
files, job queue files
and ganeti config</p></td>
<td><p>The only issue could be with system
files, which are not owned by the
current user; internal ganeti files
should be working fine</p></td>
</tr>
<tr class="row-even"><td><p>node oob</p></td>
<td><p>Out-of-band commands</p></td>
<td><p>Since these are user-defined, we can
mock them easily</p></td>
</tr>
<tr class="row-odd"><td><p>node OS
discovery</p></td>
<td><p>List the existing OSes
and their properties</p></td>
<td><p>No special privileges needed, so
works fine as-is</p></td>
</tr>
<tr class="row-even"><td><p>hooks</p></td>
<td><p>Running hooks for given
operations</p></td>
<td><p>No special privileges needed</p></td>
</tr>
<tr class="row-odd"><td><p>iallocator</p></td>
<td><p>Calling an iallocator
script</p></td>
<td><p>No special privileges needed</p></td>
</tr>
<tr class="row-even"><td><p>export/import</p></td>
<td><p>Exporting and importing
instances</p></td>
<td><p>When exporting/importing file-based
instances, this should work, as the
listening ports are dynamically
chosen</p></td>
</tr>
<tr class="row-odd"><td><p>hypervisor
validation</p></td>
<td><p>The validation of
hypervisor parameters</p></td>
<td><p>As long as the hypervisors don’t
call to privileged commands, it
should work</p></td>
</tr>
<tr class="row-even"><td><p>node powercycle</p></td>
<td><p>The ability to power
cycle a node remotely</p></td>
<td><p>Privileged, so not supported, but
anyway not very interesting for
testing</p></td>
</tr>
</tbody>
</table>
<p>It seems that much of the functionality works as is, or could work with
small adjustments, even in a non-privileged setup. The bigger problem is
the actual use of multiple node daemons per machine.</p>
<div class="section" id="multiple-noded-per-machine">
<h4>Multiple <code class="docutils literal notranslate"><span class="pre">noded</span></code> per machine<a class="headerlink" href="#multiple-noded-per-machine" title="Permalink to this headline">¶</a></h4>
<p>Currently Ganeti identifies node simply by their hostname. Since
changing this method would imply significant changes to tracking the
nodes, the proposal is to simply have as many IPs per the (single)
machine that is used for tests as nodes, and have each IP correspond to
a different name, and thus no changes are needed to the core RPC
library. Unfortunately this has the downside of requiring root rights
for setting up the extra IPs and hostnames.</p>
<p>An alternative option is to implement per-node IP/port support in Ganeti
(especially in the RPC layer), which would eliminate the root rights. We
expect that this will get implemented as a second step of this design,
but as the port is currently static will require changes in many places.</p>
<p>The only remaining problem is with sharing the <code class="docutils literal notranslate"><span class="pre">localstatedir</span></code>
structure (lib, run, log) amongst the daemons, for which we propose to
introduce an environment variable (<code class="docutils literal notranslate"><span class="pre">GANETI_ROOTDIR</span></code>) acting as a
prefix for essentially all paths. An environment variable is easier to
transport through several levels of programs (shell scripts, Python,
etc.) than a command line parameter. In Python code this prefix will be
applied to all paths in <code class="docutils literal notranslate"><span class="pre">constants.py</span></code>. Every virtual node will get
its own root directory. The rationale for this is two-fold:</p>
<ul class="simple">
<li><p>having two or more node daemons writing to the same directory might
introduce artificial scenarios not existent in real life; currently
noded either owns the entire <code class="docutils literal notranslate"><span class="pre">/var/lib/ganeti</span></code> directory or shares
it with masterd, but never with another noded</p></li>
<li><p>having separate directories allows cluster verify to check correctly
consistency of file upload operations; otherwise, as long as one node
daemon wrote a file successfully, the results from all others are
“lost”</p></li>
</ul>
<p>In case the use of an environment variable turns out to be too difficult
a compile-time prefix path could be used. This would then require one
Ganeti installation per virtual node, but it might be good enough.</p>
</div>
</div>
<div class="section" id="rapi">
<h3><code class="docutils literal notranslate"><span class="pre">rapi</span></code><a class="headerlink" href="#rapi" title="Permalink to this headline">¶</a></h3>
<p>The RAPI daemon is not privileged and furthermore we only need one per
cluster, so it presents no issues.</p>
</div>
<div class="section" id="confd">
<h3><code class="docutils literal notranslate"><span class="pre">confd</span></code><a class="headerlink" href="#confd" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">confd</span></code> has somewhat the same issues as the node daemon regarding
multiple daemons per machine, but the per-address binding still works.</p>
</div>
<div class="section" id="ganeti-watcher">
<h3><code class="docutils literal notranslate"><span class="pre">ganeti-watcher</span></code><a class="headerlink" href="#ganeti-watcher" title="Permalink to this headline">¶</a></h3>
<p>Since the startup of daemons will be customised with per-IP binds, the
watcher either has to be modified to not activate the daemons, or the
start-stop tool has to take this into account. Due to watcher’s use of
the hostname, it’s recommended that the master node is set to the
machine hostname (also a requirement for the master daemon).</p>
</div>
<div class="section" id="cli-scripts">
<h3>CLI scripts<a class="headerlink" href="#cli-scripts" title="Permalink to this headline">¶</a></h3>
<p>As long as the master node is set to the machine hostname, these should
work fine.</p>
</div>
<div class="section" id="cluster-initialisation">
<h3>Cluster initialisation<a class="headerlink" href="#cluster-initialisation" title="Permalink to this headline">¶</a></h3>
<p>It could be possible that the cluster initialisation procedure is a bit
more involved (this was not tried yet). A script will be used to set up
all necessary IP addresses and hostnames, as well as creating the
initial directory structure. Building <code class="docutils literal notranslate"><span class="pre">config.data</span></code> manually should
not be necessary.</p>
</div>
</div>
<div class="section" id="needed-tools">
<h2>Needed tools<a class="headerlink" href="#needed-tools" title="Permalink to this headline">¶</a></h2>
<p>With the above investigation results in mind, the only thing we need
are:</p>
<ul class="simple">
<li><p>a tool to setup per-virtual node tree structure of <code class="docutils literal notranslate"><span class="pre">localstatedir</span></code>
(with the help of <code class="docutils literal notranslate"><span class="pre">ensure-dirs</span></code>) and setup correctly the extra
IP/hostnames</p></li>
<li><p>changes to the startup daemon tools to launch correctly the daemons
per virtual node</p></li>
<li><p>changes to <code class="docutils literal notranslate"><span class="pre">constants.py</span></code> to override the <code class="docutils literal notranslate"><span class="pre">localstatedir</span></code> path</p></li>
<li><p>documentation for running such a virtual cluster</p></li>
<li><p>and eventual small fixes to the node daemon backend functionality, to
better separate privileged and non-privileged code</p></li>
</ul>
</div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Design for virtual clusters support</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#current-situation">Current situation</a><ul>
<li><a class="reference internal" href="#ganeti">Ganeti</a></li>
<li><a class="reference internal" href="#htools">HTools</a></li>
</ul>
</li>
<li><a class="reference internal" href="#proposed-changes">Proposed changes</a><ul>
<li><a class="reference internal" href="#masterd"><code class="docutils literal notranslate"><span class="pre">masterd</span></code></a></li>
<li><a class="reference internal" href="#noded"><code class="docutils literal notranslate"><span class="pre">noded</span></code></a><ul>
<li><a class="reference internal" href="#multiple-noded-per-machine">Multiple <code class="docutils literal notranslate"><span class="pre">noded</span></code> per machine</a></li>
</ul>
</li>
<li><a class="reference internal" href="#rapi"><code class="docutils literal notranslate"><span class="pre">rapi</span></code></a></li>
<li><a class="reference internal" href="#confd"><code class="docutils literal notranslate"><span class="pre">confd</span></code></a></li>
<li><a class="reference internal" href="#ganeti-watcher"><code class="docutils literal notranslate"><span class="pre">ganeti-watcher</span></code></a></li>
<li><a class="reference internal" href="#cli-scripts">CLI scripts</a></li>
<li><a class="reference internal" href="#cluster-initialisation">Cluster initialisation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#needed-tools">Needed tools</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="design-upgrade.html"
                        title="previous chapter">Automatized Upgrade Procedure for Ganeti</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="devnotes.html"
                        title="next chapter">Developer notes</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/design-virtual-clusters.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="devnotes.html" title="Developer notes"
             >next</a></li>
        <li class="right" >
          <a href="design-upgrade.html" title="Automatized Upgrade Procedure for Ganeti"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Ganeti 3.0.2 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Design for virtual clusters support</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015 Google Inc..
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 3.4.3.
    </div>
  </body>
</html>