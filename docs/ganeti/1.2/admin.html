<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN""http://www.w3.org/TR/html4/loose.dtd">
<HTML
><HEAD
><TITLE
>Ganeti administrator's guide</TITLE
><META
NAME="GENERATOR"
CONTENT="Modular DocBook HTML Stylesheet Version 1.79"></HEAD
><BODY
CLASS="ARTICLE"
BGCOLOR="#FFFFFF"
TEXT="#000000"
LINK="#0000FF"
VLINK="#840084"
ALINK="#0000FF"
><DIV
CLASS="ARTICLE"
><DIV
CLASS="TITLEPAGE"
><H1
CLASS="TITLE"
><A
NAME="AEN2"
>Ganeti administrator's guide</A
></H1
><HR></DIV
><DIV
CLASS="TOC"
><DL
><DT
><B
>Table of Contents</B
></DT
><DT
>1. <A
HREF="#AEN5"
>Introduction</A
></DT
><DD
><DL
><DT
>1.1. <A
HREF="#AEN17"
>Ganeti terminology</A
></DT
><DT
>1.2. <A
HREF="#AEN45"
>Prerequisites</A
></DT
></DL
></DD
><DT
>2. <A
HREF="#AEN49"
>Managing Instances</A
></DT
><DD
><DL
><DT
>2.1. <A
HREF="#AEN51"
>Adding/Removing an instance</A
></DT
><DT
>2.2. <A
HREF="#AEN119"
>Starting/Stopping an instance</A
></DT
><DT
>2.3. <A
HREF="#AEN131"
>Exporting/Importing an instance</A
></DT
></DL
></DD
><DT
>3. <A
HREF="#AEN146"
>High availability features</A
></DT
><DD
><DL
><DT
>3.1. <A
HREF="#AEN150"
>Failing over an instance</A
></DT
><DT
>3.2. <A
HREF="#AEN155"
>Replacing an instance disks</A
></DT
><DT
>3.3. <A
HREF="#AEN169"
>Failing over the master node</A
></DT
><DT
>3.4. <A
HREF="#AEN173"
>Adding/Removing nodes</A
></DT
></DL
></DD
><DT
>4. <A
HREF="#AEN183"
>Debugging Features</A
></DT
><DD
><DL
><DT
>4.1. <A
HREF="#AEN186"
>Accessing an instance's disks</A
></DT
><DT
>4.2. <A
HREF="#AEN191"
>Accessing an instance's console</A
></DT
><DT
>4.3. <A
HREF="#AEN197"
>Instance OS definitions Debugging</A
></DT
><DT
>4.4. <A
HREF="#AEN201"
>Cluster-wide debugging</A
></DT
></DL
></DD
></DL
></DIV
><P
>Documents Ganeti version 1.2</P
><DIV
CLASS="SECT1"
><HR><H2
CLASS="SECT1"
><A
NAME="AEN5"
>1. Introduction</A
></H2
><P
>Ganeti is a virtualization cluster management software. You are
    expected to be a system administrator familiar with your Linux distribution
    and the Xen virtualization environment before using it.
    </P
><P
>The various components of Ganeti all have man pages and interactive
    help. This manual though will help you getting familiar with the system by
    explaining the most common operations, grouped by related use.
    </P
><P
>After a terminology glossary and a section on the prerequisites
    needed to use this manual, the rest of this document is divided in three
    main sections, which group different features of Ganeti:
      <P
></P
><UL
><LI
><P
>Instance Management</P
></LI
><LI
><P
>High Availability Features</P
></LI
><LI
><P
>Debugging Features</P
></LI
></UL
>
    </P
><DIV
CLASS="SECT2"
><HR><H3
CLASS="SECT2"
><A
NAME="AEN17"
>1.1. Ganeti terminology</A
></H3
><P
>        This section provides a small introduction to Ganeti terminology, which
        might be useful to read the rest of the document.

        <DIV
CLASS="GLOSSLIST"
><DL
><DT
><B
>Cluster</B
></DT
><DD
><P
>                A set of machines (nodes) that cooperate to offer a
                coherent highly available virtualization service.
              </P
></DD
><DT
><B
>Node</B
></DT
><DD
><P
>                A physical machine which is member of a cluster.
                Nodes are the basic cluster infrastructure, and are
                not fault tolerant.
              </P
></DD
><DT
><B
>Master node</B
></DT
><DD
><P
>                The node which controls the Cluster, from which all
                Ganeti commands must be given.
              </P
></DD
><DT
><B
>Instance</B
></DT
><DD
><P
>                A virtual machine which runs on a cluster. It can be a
                fault tolerant highly available entity.
              </P
></DD
><DT
><B
>Pool</B
></DT
><DD
><P
>                A pool is a set of clusters sharing the same network.
              </P
></DD
><DT
><B
>Meta-Cluster</B
></DT
><DD
><P
>                Anything that concerns more than one cluster.
              </P
></DD
></DL
></DIV
>
      </P
></DIV
><DIV
CLASS="SECT2"
><HR><H3
CLASS="SECT2"
><A
NAME="AEN45"
>1.2. Prerequisites</A
></H3
><P
>        You need to have your Ganeti cluster installed and configured before
        you try any of the commands in this document. Please follow the
        <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>Ganeti installation tutorial</I
></SPAN
> for instructions on
        how to do that.
      </P
></DIV
></DIV
><DIV
CLASS="SECT1"
><HR><H2
CLASS="SECT1"
><A
NAME="AEN49"
>2. Managing Instances</A
></H2
><DIV
CLASS="SECT2"
><H3
CLASS="SECT2"
><A
NAME="AEN51"
>2.1. Adding/Removing an instance</A
></H3
><P
>        Adding a new virtual instance to your Ganeti cluster is really easy.
        The command is:

        <PRE
CLASS="SYNOPSIS"
>gnt-instance add -n <TT
CLASS="REPLACEABLE"
><I
>TARGET_NODE</I
></TT
> -o <TT
CLASS="REPLACEABLE"
><I
>OS_TYPE</I
></TT
> -t <TT
CLASS="REPLACEABLE"
><I
>DISK_TEMPLATE</I
></TT
> <TT
CLASS="REPLACEABLE"
><I
>INSTANCE_NAME</I
></TT
></PRE
>

        The instance name must be resolvable (e.g. exist in DNS) and
        of course map to an address in the same subnet as the cluster
        itself. Options you can give to this command include:

      <P
></P
><UL
><LI
><P
>The disk size (<CODE
CLASS="OPTION"
>-s</CODE
>)</P
></LI
><LI
><P
>The swap size (<CODE
CLASS="OPTION"
>--swap-size</CODE
>)</P
></LI
><LI
><P
>The memory size (<CODE
CLASS="OPTION"
>-m</CODE
>)</P
></LI
><LI
><P
>The number of virtual CPUs (<CODE
CLASS="OPTION"
>-p</CODE
>)</P
></LI
><LI
><P
>The instance ip address (<CODE
CLASS="OPTION"
>-i</CODE
>) (use the value
            <TT
CLASS="LITERAL"
>auto</TT
> to make Ganeti record the address from
            dns)</P
></LI
><LI
><P
>The bridge to connect the instance to (<CODE
CLASS="OPTION"
>-b</CODE
>),
            if you don't want to use the default one</P
></LI
></UL
>
      </P
><P
>There are four types of disk template you can choose from:</P
><P
></P
><DIV
CLASS="VARIABLELIST"
><DL
><DT
>diskless</DT
><DD
><P
>The instance has no disks. Only used for special purpouse
              operating systems or for testing.</P
></DD
><DT
>plain</DT
><DD
><P
>The instance will use LVM devices as backend for its disks.
              No redundancy is provided.</P
></DD
><DT
>local_raid1</DT
><DD
><P
>A local mirror is set between LVM devices to back the
              instance. This provides some redundancy for the instance's
              data.</P
></DD
><DT
>remote_raid1</DT
><DD
><P
><SPAN
CLASS="strong"
><B
CLASS="EMPHASIS"
>Note:</B
></SPAN
> This is only
              valid for multi-node clusters using drbd 0.7.</P
><P
>              A mirror is set between the local node and a remote one, which
              must be specified with the second value of the --node option. Use
              this option to obtain a highly available instance that can be
              failed over to a remote node should the primary one fail.
            </P
></DD
><DT
>drbd</DT
><DD
><P
><SPAN
CLASS="strong"
><B
CLASS="EMPHASIS"
>Note:</B
></SPAN
> This is only
              valid for multi-node clusters using drbd 8.0.</P
><P
>              This is similar to the
              <TT
CLASS="REPLACEABLE"
><I
>remote_raid1</I
></TT
> option, but uses
              new features in drbd 8 to simplify the device
              stack. From a user's point of view, this will improve
              the speed of the <B
CLASS="COMMAND"
>replace-disks</B
>
              command and (in future versions) provide more
              functionality.
            </P
></DD
></DL
></DIV
><P
>        For example if you want to create an highly available instance use the
        remote_raid1 or drbd disk templates:
        <PRE
CLASS="SYNOPSIS"
>gnt-instance add -n <TT
CLASS="REPLACEABLE"
><I
>TARGET_NODE</I
></TT
>[<SPAN
CLASS="OPTIONAL"
>:<TT
CLASS="REPLACEABLE"
><I
>SECONDARY_NODE</I
></TT
></SPAN
>] -o <TT
CLASS="REPLACEABLE"
><I
>OS_TYPE</I
></TT
> -t remote_raid1 \
  <TT
CLASS="REPLACEABLE"
><I
>INSTANCE_NAME</I
></TT
></PRE
>

      </P
><P
>        To know which operating systems your cluster supports you can use
        <PRE
CLASS="SYNOPSIS"
>gnt-os list</PRE
>
      </P
><P
>        Removing an instance is even easier than creating one. This operation
        is non-reversible and destroys all the contents of your instance. Use
        with care:

        <PRE
CLASS="SYNOPSIS"
>gnt-instance remove <TT
CLASS="REPLACEABLE"
><I
>INSTANCE_NAME</I
></TT
></PRE
>
      </P
></DIV
><DIV
CLASS="SECT2"
><HR><H3
CLASS="SECT2"
><A
NAME="AEN119"
>2.2. Starting/Stopping an instance</A
></H3
><P
>        Instances are automatically started at instance creation time. To
        manually start one which is currently stopped you can run:

        <PRE
CLASS="SYNOPSIS"
>gnt-instance startup <TT
CLASS="REPLACEABLE"
><I
>INSTANCE_NAME</I
></TT
></PRE
>

        While the command to stop one is:

        <PRE
CLASS="SYNOPSIS"
>gnt-instance shutdown <TT
CLASS="REPLACEABLE"
><I
>INSTANCE_NAME</I
></TT
></PRE
>

        The command to see all the instances configured and their status is:

        <PRE
CLASS="SYNOPSIS"
>gnt-instance list</PRE
>

      </P
><P
>        Do not use the xen commands to stop instances. If you run for
        example xm shutdown or xm destroy on an instance Ganeti will
        automatically restart it (via the
        <SPAN
CLASS="CITEREFENTRY"
><SPAN
CLASS="REFENTRYTITLE"
>ganeti-watcher</SPAN
>(8)</SPAN
>)
      </P
></DIV
><DIV
CLASS="SECT2"
><HR><H3
CLASS="SECT2"
><A
NAME="AEN131"
>2.3. Exporting/Importing an instance</A
></H3
><P
>        You can create a snapshot of an instance disk and Ganeti
        configuration, which then you can backup, or import into
        another cluster. The way to export an instance is:

        <PRE
CLASS="SYNOPSIS"
>gnt-backup export -n <TT
CLASS="REPLACEABLE"
><I
>TARGET_NODE</I
></TT
> <TT
CLASS="REPLACEABLE"
><I
>INSTANCE_NAME</I
></TT
></PRE
>

        The target node can be any node in the cluster with enough
        space under <TT
CLASS="FILENAME"
>/srv/ganeti</TT
>
        to hold the instance image. Use the
        <CODE
CLASS="OPTION"
>--noshutdown</CODE
> option to snapshot an instance
        without rebooting it. Any previous snapshot of the same
        instance existing cluster-wide under <TT
CLASS="FILENAME"
>/srv/ganeti</TT
> will be removed by
        this operation: if you want to keep them move them out of the
        Ganeti exports directory.
      </P
><P
>        Importing an instance is similar to creating a new one. The command is:

        <PRE
CLASS="SYNOPSIS"
>gnt-backup import -n <TT
CLASS="REPLACEABLE"
><I
>TARGET_NODE</I
></TT
> -t <TT
CLASS="REPLACEABLE"
><I
>DISK_TEMPLATE</I
></TT
> --src-node=<TT
CLASS="REPLACEABLE"
><I
>NODE</I
></TT
> --src-dir=DIR INSTANCE_NAME</PRE
>

        Most of the options available for the command
        <SPAN
CLASS="emphasis"
><I
CLASS="EMPHASIS"
>gnt-instance add</I
></SPAN
> are supported here too.

      </P
></DIV
></DIV
><DIV
CLASS="SECT1"
><HR><H2
CLASS="SECT1"
><A
NAME="AEN146"
>3. High availability features</A
></H2
><DIV
CLASS="NOTE"
><P
></P
><TABLE
CLASS="NOTE"
WIDTH="100%"
BORDER="0"
><TR
><TD
WIDTH="25"
ALIGN="CENTER"
VALIGN="TOP"
><IMG
SRC="../images/note.gif"
HSPACE="5"
ALT="Note"></TD
><TD
ALIGN="LEFT"
VALIGN="TOP"
><P
>This section only applies to multi-node clusters.</P
></TD
></TR
></TABLE
></DIV
><DIV
CLASS="SECT2"
><HR><H3
CLASS="SECT2"
><A
NAME="AEN150"
>3.1. Failing over an instance</A
></H3
><P
>        If an instance is built in highly available mode you can at
        any time fail it over to its secondary node, even if the
        primary has somehow failed and it's not up anymore. Doing it
        is really easy, on the master node you can just run:

        <PRE
CLASS="SYNOPSIS"
>gnt-instance failover <TT
CLASS="REPLACEABLE"
><I
>INSTANCE_NAME</I
></TT
></PRE
>

        That's it. After the command completes the secondary node is
        now the primary, and vice versa.
      </P
></DIV
><DIV
CLASS="SECT2"
><HR><H3
CLASS="SECT2"
><A
NAME="AEN155"
>3.2. Replacing an instance disks</A
></H3
><P
>        So what if instead the secondary node for an instance has
        failed, or you plan to remove a node from your cluster, and
        you failed over all its instances, but it's still secondary
        for some? The solution here is to replace the instance disks,
        changing the secondary node. This is done in two ways, depending on the disk template type. For <TT
CLASS="LITERAL"
>remote_raid1</TT
>:

        <PRE
CLASS="SYNOPSIS"
>gnt-instance replace-disks <CODE
CLASS="OPTION"
>-n <TT
CLASS="REPLACEABLE"
><I
>NEW_SECONDARY</I
></TT
></CODE
> <TT
CLASS="REPLACEABLE"
><I
>INSTANCE_NAME</I
></TT
></PRE
>

        and for <TT
CLASS="LITERAL"
>drbd</TT
>:
        <PRE
CLASS="SYNOPSIS"
>gnt-instance replace-disks <CODE
CLASS="OPTION"
>-s</CODE
> <CODE
CLASS="OPTION"
>-n <TT
CLASS="REPLACEABLE"
><I
>NEW_SECONDARY</I
></TT
></CODE
> <TT
CLASS="REPLACEABLE"
><I
>INSTANCE_NAME</I
></TT
></PRE
>

        This process is a bit longer, but involves no instance
        downtime, and at the end of it the instance has changed its
        secondary node, to which it can if necessary be failed over.
      </P
></DIV
><DIV
CLASS="SECT2"
><HR><H3
CLASS="SECT2"
><A
NAME="AEN169"
>3.3. Failing over the master node</A
></H3
><P
>        This is all good as long as the Ganeti Master Node is
        up. Should it go down, or should you wish to decommission it,
        just run on any other node the command:

        <PRE
CLASS="SYNOPSIS"
>gnt-cluster masterfailover</PRE
>

        and the node you ran it on is now the new master.
      </P
></DIV
><DIV
CLASS="SECT2"
><HR><H3
CLASS="SECT2"
><A
NAME="AEN173"
>3.4. Adding/Removing nodes</A
></H3
><P
>        And of course, now that you know how to move instances around,
        it's easy to free up a node, and then you can remove it from
        the cluster:

        <PRE
CLASS="SYNOPSIS"
>gnt-node remove <TT
CLASS="REPLACEABLE"
><I
>NODE_NAME</I
></TT
></PRE
>

        and maybe add a new one:

        <PRE
CLASS="SYNOPSIS"
>gnt-node add [<SPAN
CLASS="OPTIONAL"
><CODE
CLASS="OPTION"
>--secondary-ip=<TT
CLASS="REPLACEABLE"
><I
>ADDRESS</I
></TT
></CODE
></SPAN
>] <TT
CLASS="REPLACEABLE"
><I
>NODE_NAME</I
></TT
>

      </PRE
>
      </P
></DIV
></DIV
><DIV
CLASS="SECT1"
><HR><H2
CLASS="SECT1"
><A
NAME="AEN183"
>4. Debugging Features</A
></H2
><P
>      At some point you might need to do some debugging operations on
      your cluster or on your instances. This section will help you
      with the most used debugging functionalities.
    </P
><DIV
CLASS="SECT2"
><HR><H3
CLASS="SECT2"
><A
NAME="AEN186"
>4.1. Accessing an instance's disks</A
></H3
><P
>        From an instance's primary node you have access to its
        disks. Never ever mount the underlying logical volume manually
        on a fault tolerant instance, or you risk breaking
        replication. The correct way to access them is to run the
        command:

        <PRE
CLASS="SYNOPSIS"
>gnt-instance activate-disks <TT
CLASS="REPLACEABLE"
><I
>INSTANCE_NAME</I
></TT
></PRE
>

        And then access the device that gets created.  After you've
        finished you can deactivate them with the deactivate-disks
        command, which works in the same way.
      </P
></DIV
><DIV
CLASS="SECT2"
><HR><H3
CLASS="SECT2"
><A
NAME="AEN191"
>4.2. Accessing an instance's console</A
></H3
><P
>        The command to access a running instance's console is:

        <PRE
CLASS="SYNOPSIS"
>gnt-instance console <TT
CLASS="REPLACEABLE"
><I
>INSTANCE_NAME</I
></TT
></PRE
>

        Use the console normally and then type
        <KBD
CLASS="USERINPUT"
>^]</KBD
> when done, to exit.
      </P
></DIV
><DIV
CLASS="SECT2"
><HR><H3
CLASS="SECT2"
><A
NAME="AEN197"
>4.3. Instance OS definitions Debugging</A
></H3
><P
>        Should you have any problems with operating systems support
        the command to ran to see a complete status for all your nodes
        is:

        <PRE
CLASS="SYNOPSIS"
>gnt-os diagnose</PRE
>

      </P
></DIV
><DIV
CLASS="SECT2"
><HR><H3
CLASS="SECT2"
><A
NAME="AEN201"
>4.4. Cluster-wide debugging</A
></H3
><P
>        The gnt-cluster command offers several options to run tests or
        execute cluster-wide operations. For example:

      <PRE
CLASS="SCREEN"
>gnt-cluster command
gnt-cluster copyfile
gnt-cluster verify
gnt-cluster getmaster
gnt-cluster version
      </PRE
>

        See the man page <SPAN
CLASS="CITEREFENTRY"
><SPAN
CLASS="REFENTRYTITLE"
>gnt-cluster</SPAN
>(8)</SPAN
> to know more about
        their usage.
      </P
></DIV
></DIV
></DIV
></BODY
></HTML
>